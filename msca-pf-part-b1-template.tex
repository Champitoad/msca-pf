\documentclass[12pt,draftproposal]{msca-pf}
% {{{ packages

\usepackage[left=15mm,right=15mm,bottom=20mm,top=20mm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{prftree}
\usepackage{graphicx}
\usepackage{mathpartir}

% better environments
\usepackage[nameinlink, noabbrev]{cleveref}
\usepackage[shortlabels]{enumitem}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}

% better typography
\usepackage[activate={true,nocompatibility}, % activate protrusion and font expansion
            final,              % enable microtype, use draft to disable
            tracking=true,
            factor=1100,        % more protrusion
            stretch=10,         % smaller values (default 20, 20) to avoid blurring
            shrink=10]{microtype}
\SetTracking{encoding={*}, shape=sc}{40}

% bibliography
\usepackage[style=mla,backend=biber]{biblatex}

% }}}

% {{{ formatting

% NOTE: this needs to be kept so that the sections match the template!
\setcounter{section}{0}

% }}}

% {{{ commands

% add your own fancy commands
% \NewDocumentCommand \mycmd { m } {\textbf{#1}}

\graphicspath{{./graphics}} % Paths whereimages are looked for
\newcommand{\includepdf}[2]{\vcenter{\hbox{\includegraphics[width=#1]{#2.pdf}}}}

\newcommand{\fullwidthbox}[1]{%
    \noindent\makebox[\textwidth]{%
        \fbox{%
            \begin{minipage}{\dimexpr\textwidth-2\fboxsep-2\fboxrule\relax}
                \centering
                #1
            \end{minipage}%
        }%
    }%
}

\newcommand{\proj}{\small\textsc{ScrollNets}}
\newcommand{\CH}[1]{$\mathsf{C#1}$}
\newcommand{\KO}[1]{$\mathsf{KO#1}$}
\newcommand{\WP}[1]{$\mathsf{WP#1}$}
\newcommand{\TO}[1]{$\mathsf{TO#1}$}
\newcommand{\xstep}[1]{\xrightarrow{#1}}

% }}}

% {{{ title

\title{Part B-1}
\author{Pablo Donato}
\date{\today}

% NOTE: update these as necessary
\mscaidentifier{HORIZON-MSCA-2025-PF-01}
\mscaproject{\textsc{ScrollNets}}

% }}}

% {{{ bibliography

% \usepackage{filecontents}% to embed the file `myreferences.bib` in your `.tex` file

% \begin{filecontents}{myreferences.bib}
% @online{foo12,
%   year = {2012},
%   title = {footnote-reference-using-european-system},
%   url = {http://tex.stackexchange.com/questions/69716/footnote-reference-using-european-system},
% }
% \end{filecontents}

% \addbibresource{MSCA.bib}
\bibliography{MSCA.bib}

% }}}

\begin{document}

\maketitle

% \textit{The text in each section is provided only as guidance and should be deleted
% in the final application (including this text). The tags in the section titles
% and at the end of certain sections should be \textbf{kept as is}. They are used for
% automatic document processing and are highly recommended by the programme.}

% \textit{When in doubt, always consult the official template and programme guide!}

\section{Excellence \mscatag{REL-EVA-RE}}
\label{sc:excellence}

\subsection{Quality and pertinence of the project's research and innovation objectives}
\label{ssc:excellence:quality}

\textbf{Proof assistants} --- also called \emph{interactive theorem provers} (ITPs) --- are software
tools used to rigorously verify formal modelling and reasoning. Contemporary systems such as
\emph{Rocq}, \emph{Lean}, and
\emph{Isabelle}\footcite{the_rocq_development_team_2025_15149629,10.1007/978-3-030-79876-5_37,nipkow2002isabelle}
offer powerful frameworks for constructing formal specifications and proofs: they have been used
successfully in various applications, ranging from the verification of advanced theorems in
mathematics to the certification of complex software artifacts such as programming language
compilers, operating system kernels and cryptographic
protocols\footcite{gonthierFormalProofFour2008,leroyFormalVerificationRealistic2009,kleinSeL4FormalVerification2009,Barthe2014}.
Yet they remain notoriously difficult to learn and use, limiting broader adoption in various
settings where they could bring transformative societal impact, such as:
\begin{itemize}
    \item \textbf{mathematics education}, where they could act as a unifying medium for interactive
    exploration and understanding of mathematical concepts, fostering closer collaboration amongst
    students and offloading some teaching burden (e.g. grading) through
    automation\footcite{minhResearchReportProof2024};
    \item \textbf{formal verification}, where they could bring higher standards of quality assurance
    (QA) to businesses that rely on complex hardware and software systems, especially in
    safety-critical industries such as healthcare, transportation and energy;
    \item \textbf{artificial intelligence (AI) safety}, where the uncertainty inherent to current
    technologies based on probabilistic techniques such as large language models (LLMs) could be
    mitigated by the exact logical reasoning capabilities of ITPs, an approach sometimes termed
    \emph{neurosymbolic AI}.
\end{itemize}
In view of this large potential for applications, it is natural to ask what exactly limits adoption
of the current generation of ITPs. The recent surge of interest arising both in academia and
industry --- in great part due to the popularity of the Lean language and its Mathlib library ---
suggests that social factors such as public communication, community building, and vast amounts of
expository content and learning resources all play an important role in the widespread appropriation
of this complex technology. Even more recently, the promise of a new kind of generative AI free from
so-called ``hallucinations'' that could aid in accelerating scientific discoveries has been a
powerful narrative attracting much attention and funding\footcite{metzMathPathChatbots2024}.

However, many researchers in the field agree that current ITPs suffer from more \emph{foundational}
issues that affect directly their accessibility and ease of use, as well as their ability to scale
to larger developments. While these issues are quite diverse in nature, a recurring theme since the
birth of the technology in the 60s is the overwhelming \textbf{bureaucracy} involved in
formalization efforts: formal proofs require a level of care and detail that is far superior and
much more time consuming than what is expected from informal paper proofs. This has been measured by
the so-called \emph{DeBruijn factor} comparing the size of formal and informal proofs, often
reaching a value of 4 on average\footcite{debruijn_factor}.

The main approach to tame this complexity has been to \emph{automate} the various processes involved
in formalization, which fall roughly within two categories: \emph{elaboration}, concerned with the
translation of requirements expressed in natural language or mathematical notations into precise
logical specifications; and \emph{synthesis}, where the system attempts to automatically generate
(parts of) proofs and programs meeting these specifications. Progress on both fronts is currently
being made with the help of state-of-the-art machine learning techniques, including
LLMs\footcite{blaauwbroekLearningGuidedAutomated2024}. More theoretical research has also been
pursued in \textbf{type theory}, the field studying the logical formalisms at the foundation of all
modern ITPs. They are the ultimate backbone on which relies our \emph{trust} in the output of these
systems, and thus a key differentiator with respect to purely probabilistic approaches to
(generative) AI.
% In particular, the influential program of \emph{homotopy type theory} kickstarted by Fields medalist
% Vladimir Voevodsky has exhibited new ways to understand and mechanize the concept of
% \emph{equality}, which is known as an important weakness of traditional type theories.
% Type-theoretical foundations are the ultimate backbone on which relies our \emph{trust} in the
% output of ITPs, and thus a key differentiator with respect to purely probabilistic approaches to
% (generative) AI.

However, little attention has been devoted by the ITP community to another discipline closely
related to type theory: \textbf{proof theory}. In particular, \emph{structural} proof theory is its
branch concerned with the study of combinatorial structures for representing and manipulating
proofs. One can identify mainly three motivations for this study:
\begin{description}
    \item[Challenge 1 (\CH{1})] is the fundamental problem of \textbf{proof identity}, also
    known as Hilbert's 24\textsuperscript{th} problem\footcite{strasburger-problem-2019}. It aims to
    answer the philosophical question ``what is a proof?'', and the mathematical question ``when are
    two proofs equal?''. It is thus intimately related to \emph{homotopy type theory} which also
    investigates the structure of \emph{equality}, a known weakness of many type theories.

    \item[Challenge 2 (\CH{2})] is to find proof systems for \textbf{non-standard logics} ---
    such as \emph{modal}, \emph{intermediate}, \emph{substructural} and \emph{fixpoint} logics ---
    satisfying good enough properties as to render an algorithmic treatment of these logics
    tractable. The most important property in this respect is that of \textbf{cut elimination},
    which is essential both to reduce the complexity of \emph{proof search} (proof \emph{synthesis}
    in ITP terminology), and to ensure productivity of \emph{program execution} through the
    \textbf{Curry-Howard correspondence} (CHC) between proofs and programs. The CHC is also at the
    heart of the \emph{calculus of inductive constructions} (CoIC), which is the type theory used by
    the two leading proof assistants Rocq and Lean. Researchers are increasingly interested in
    type-theoretic formulations of these logics as they provide expressive languages for specifying
    behaviors of programs that go beyond pure functions, including effects (modal logics),
    resource-sensitivity (modal and substructural logics) and recursion (modal and fixpoint
    logics)\footcite{tangModalEffectTypes2025,marshallLinearityUniquenessEntente2022,cloustonGuardedLambdaCalculusProgramming2017}.
    
    \item[Challenge 3 (\CH{3})] is to improve the \textbf{efficiency} of computational
    procedures on proofs, but also on programs through the CHC. A well-established principle in
    computer science and software engineering is that choosing appropriate data structures for a
    problem can lead to orders-of-magnitude improvements in efficiency. Finding the right data
    structures for such general classes of objects as proofs and programs is thus a very enticing
    goal with wide implications, including faster automation in ITPs.
\end{description}

In the past decades, two families of proof formalisms have emerged to tackle these challenges:
\begin{description}
    \item \textbf{Graphical proof systems} represent proof objects as \emph{graphs} instead of
    \emph{trees} of inference rules.
    % Many programming systems incorporate graph representations of programs in their compilation
    % pipeline in order to optimize the flow of computation, including popular machine learning
    % frameworks based on neural networks such as TensorFlow and PyTorch. Indeed, graphs appear
    % naturally when one wants to abstract from the order in which operations are sequenced, to
    % leverage \emph{parallelism} or to maximize \emph{sharing} of computations.
    \emph{Proof nets}\footcite{girard-linear-1987} are one of the first graphical proof formalisms,
    meant to reduce the bureauceacy of proofs in linear logic (\CH{2}) in order to identify their
    essence (\CH{1}). Further developments stemming from proof nets like the \emph{geometry of
    interaction} and \emph{interaction nets} have found applications in program optimization for
    hardware synthesis and parallelized
    execution\footcite{ghicaGeometrySynthesisStructured2007,mackieInteractionNetImplementation2011}
    (\CH{3}). The \emph{combinatorial proofs} of Hughes are direct decendants of proof nets mainly
    concerned with \CH{1}\footcite{Hughes_2006}, and \emph{string diagrams} from category theory have
    been applied to logic and programming languages, with well-known connections to proof
    nets\footcite{piedeleuIntroductionStringDiagrams2025}.

    \item \textbf{Deep inference} generalizes Gentzen-style proof systems by allowing inference
    rules to be applied at any depth inside of a formula, rather than being restricted to its
    top-level logical connective. The terminology of ``deep inference'' was proposed by Alessio
    Guglielmi, who invented the \emph{calculus of structures} to overcome the inability of sequent
    calculus to capture the substructural logic $\mathsf{MV}$\footcite{Guglielmi1999ACO}. Since
    then, calculi of structures and so-called \emph{nested sequent calculi} have been introduced to
    give proof systems enjoying cut-elimination to most substructural, modal and intermediate
    logics\footcite{kuznets_maehara-style_2019,postniece_proof_2010} (\CH{2}). Deep inference has also
    been used in the study of proof complexity, providing in some cases exponential speedup over
    sequent calculus with respect to proof size, as well as quasipolynomial-time
    cut-elimination\footcite{dasRelativeProofComplexity2015a,bruscoliQuasipolynomialNormalisationDeep2016a}
    (\CH{3}). Lastly, many deep inference formalisms enjoy CHC-style interpretations with variants of
    $\lambda$-calculus, which also improve space
    efficiency\footcite{guenot_nested_2013,gundersenAtomicLambdaCalculus2013}.
\end{description}

The experienced researcher (ER) has accumulated significant knowledge of graphical and deep
inference proof systems, as well as their applications to ITPs. This expertise was developed during
his PhD thesis\footcite{donatoDeepInferenceGraphical2024} titled ``Deep Inference for Graphical
Theorem Proving'', where he designed various proof formalisms that enable a novel approach to
interactive theorem proving based on \textbf{direct manipulation} of logical statements in a
graphical user interface (GUI). This extends earlier works on \emph{Proof-by-Pointing}\footcite{PbP}
and \emph{Proof-by-Linking}\footcite{Chaudhuri2013} where proofs are constructed through
\emph{click} and \emph{drag-and-drop} gestures on formulas, to a more encompassing paradigm termed
\emph{Proof-by-Action} (PbA). The goal is to improve accessibility and usability of ITPs by focusing
on better principles for \emph{human interaction}, complementing more mainstream research around
machine automation. Applying a mixture of graphical and deep inference proof theory to that effect
is a highly original endeavor, with no similar efforts in the contemporary research landscape.

\begin{figure}
  \captionsetup[subfigure]{justification=centering}
  \centering
  \begin{subfigure}[b]{0.64\textwidth}
    \begin{mathpar}
      \includepdf{2cm}{modusponens1}
      ~~~\xstep{\mathsf{Deit}}~~~
      \includepdf{2cm}{modusponens2}
      ~~~\xstep{\mathsf{Close}}~~~
      \includepdf{1.25cm}{modusponens3}
      ~~~\xstep{\mathsf{Del}}~~~
      \includepdf{0.25cm}{modusponens4}
    \end{mathpar}
    \caption{Dynamic rewriting from premiss $a \wedge (a \Rightarrow b)$ to conclusion $b$}
    \label{fig:modus-ponens-dynamic}
  \end{subfigure}
  \begin{subfigure}[b]{0.35\textwidth}
    \centering
    $\includepdf{2.25cm}{modusponens-scrollnet}$
    \caption{Static representation of rules as arrows in a bigraph}
    \label{fig:modus-ponens-static}
  \end{subfigure}
  \caption{Proof of \textit{modus ponens} $a \wedge (a \Rightarrow b) \vdash b$ in scroll nets.
  Intuitionistic implication $a \Rightarrow b$ is represented topologically by a \emph{scroll}, i.e.
  two nested ellipses that intersect exactly at one point, where the outer gray \emph{outloop}
  (resp. inner white \emph{inloop}) contains the antecedant $a$ (resp. consequent $b$).}
  \label{fig:modus-ponens}
\end{figure}

In continuation of this programme, the ER has introduced in his last
preprint\footcite{donatoScrollNets2025} a new graphical framework called \textbf{scroll nets}. It is
based on a long forgotten diagrammatic proof system called \emph{existential graphs} (EGs), invented
by the famous philosopher and logician Charles Sanders Peirce at the dusk of the
19\textsuperscript{th} century --- thus predating the very existence of proof theory and computer
science. Proofs in EGs are defined by a small set of inference rules that \emph{dynamically} rewrite
diagrams in contexts of arbitrary depth (Fig.~\ref{fig:modus-ponens-dynamic}), thus combining
features of both deep inference and string diagrams\footcite{bonchi_diagrammatic_2024}. Scroll nets
provide a \emph{static} way to represent proofs in EGs by recording explicitly applications of
inference rules in a \emph{directed graph} (Fig.~\ref{fig:modus-ponens-static}), combining the
type-theoretic methodology of internalizing inference rules inside judgments with a graphical
structure similar to proof nets and combinatorial proofs. Crucially, this graph shares the same
nodes as the (tree-shaped) statements involved in the proof, making scroll nets a more compact
representation than other graphical proof structures, but also surprisingly a variant of the notion
of \emph{bigraph}. Bigraphs were introduced by Milner as a foundational combinatorial structure
encompassing most models of concurrent/parallel computation, including Petri nets and his own CCS
and $\pi$-calculus\footcite{milnerBigraphicalReactiveSystems2001}. In his preprint, the ER shows how
scroll nets naturally subsume the simply-typed $\lambda$-calculus --- the common kernel of all type
theories used in ITPs --- by identifying a generalization of the notion of \emph{detour} from
natural deduction that abstracts away the shape of formulas.

All these discoveries hint toward the potential of scroll nets as a very expressive framework for
both proof theory and type theory, unifying features found in most of the formalisms that have
emerged from the two disciplines in a natural and efficient way. Moreover, the ER's vision is to
exploit the diagrammatic nature of scroll nets to redesign not only the \emph{backend} but also the
\emph{frontend} of ITPs, making them the \emph{interaction
substrate}\footcite{mackayInteractionSubstratesCombining2025} of a new kind of GUI in the PbA
paradigm. Indeed, what crucially distinguishes scroll nets from other deep inference or graphical
proof formalisms is their suitability for \emph{interactive manipulation}: every inference rule
possesses a natural spatial interpretation as a \emph{gesture} on a logical statement, either
inserting/erasing a statement at a designated location through \emph{pointing} (looping arrows in
Fig.~\ref{fig:modus-ponens-static}), or (un)copying to/from some location through
\emph{drag-and-drop} (non-looping arrows in Fig.~\ref{fig:modus-ponens-static}). This natural
semantics of gestures as a means of manipulating located objects is very familiar to users of modern
GUIs in virtually every domain, and could lead to a \textbf{groundbreaking ``no-code'' approach to
interactive theorem proving} that is much more intuitive than current textual interfaces.

Given the early stage of the theory of scroll nets and the expertise of the Theory of Computation
group at Birmingham hosting the ER, the {\proj} project will progress towards this vision by
focusing on the following Key Objectives:

% One goal is to make automation (in particular synthesis) easier to understand
% for humans, so as to tighten the interaction loop and thus enhance the collaboration between the
% user and the system. Having more readable inputs and outputs is also crucial to enable \emph(audits)
% of formal developments by external authorities, for instance in the certification of safety-critical
% software by governmental agencies.

% \setlength{\fboxsep}{5pt}
% \fullwidthbox{
    \begin{description}
        \item[(\KO{1})] extend the theory of scroll nets to account for \textbf{richer logics}, beyond minimal
        implicative logic;
        \item[(\KO{2})] find natural and efficient \textbf{translations} of state-of-the-art proof
        systems and typed models of computation into scroll nets.
    \end{description}
% }

This should support the following very ambitious long-term goal of the project:

\setlength{\fboxsep}{5pt}
\fullwidthbox{\textit{ 
    Establish \textbf{scroll nets} as the foundation for a new generation of ITPs
    that support \textbf{interactive refinement} of formal specifications, proofs and programs through
    \textbf{diagrammatic manipulations}.
}}

% At a minimum, address the following aspects:

% \begin{itemize}
%     \item Describe the quality and pertinence of the R\&I objectives; are the
%     objectives measurable and verifiable? Are they realistically achievable?

%     \item Describe how your project goes beyond the state-of-the-art, and the
%     extent to which the proposed work is ambitious.
% \end{itemize}

\subsection{Soundness of the proposed methodology}
\label{ssc:excellence:methodology}

The research objectives of {\proj} are organised into five technical work packages, detailed below.
The core theory will be developed in \WP{1} and then extended to richer logics in \WP{2}, \WP{3} and
\WP{4}, meeting \KO{1}. This will culminate in \WP{5} with the study of translations from
state-of-the-art models of computation, achieving \KO{2}.
\begin{enumerate}
    \item \WP{1} will work in the restricted and well-understood setting of minimal implicative
    logic, with the aim to prove formally two key meta-theoretic properties of scroll nets:
    \begin{itemize}
        \item \textbf{Normalization} is a standard property of structural proof
        systems that asserts the existence (and sometimes unicity) of a \emph{normal form} associated to
        every proof, often exhibited constructively by a terminating (sometimes confluent) rewriting
        system. The ER has already sketched in his preprint such a rewriting system, called \emph{detour
        elimination}. It will need a rigorous mathematical analysis to reach its definitive form and
        obtain more insights on its computational properties. We expect that detour elimination will be
        both terminating and confluent as well as highly parallelizable, in analogy with normalization
        procedures for other graphical formalisms like proof nets and interaction nets.

        \item \textbf{Sequentialization} originates from proof nets: it is a fundamental theorem establishing the
        \emph{canonicity} of proof nets as a representation of proofs in (some fragments of) linear
        logic, quotienting proofs in sequent calculus modulo rule permutations. The ER has observed a
        similar phenomenon in scroll nets, where multiple \emph{proof traces} (as in
        Fig.~\ref{fig:modus-ponens-dynamic}) which only vary in the order of inferences can build the
        same scroll net (as in Fig.~\ref{fig:modus-ponens-static}). Moreover, there is a bijective
        correspondence between the inferences in a proof trace and their static representation as edges
        in the associated scroll net, which preserves enough information to enable efficient
        reconstruction of possible traces from the latter. \WP{1} will workout the details of the
        sequentialization theorem and define formally such a reconstruction algorithm, which is not
        known to have any equivalent in the proof-theoretic landscape.
    \end{itemize}
    
    \item Oostra already identified how to capture intuitionistic disjunction in EGs, by considering
    a \emph{horizontal} generalization of the scroll where one can have an arbitrary number $h$ of
    inloops attached to the same outloop\footcite{oostra_graficos_2010}. The ER has performed
    preliminary experiments on a further \emph{vertical} generalization of the scroll where inloops
    can be recursively attached to other inloops, leading to a notion of $(h,v)$-scroll with $h$
    (resp. $v$) counting the maximum number of inloops in horizontal (resp. vertical) dimension.
    Then intuitionistic disjunction and falsehood correspond to the cases where $h > 1$ and $h < 1$,
    while intuitionistic \emph{subtraction} (also called \emph{exclusion} or \emph{co-implication})
    and negation correspond to the cases where $v > 1$ and $v < 1$. This is illustrated in
    Fig.~\ref{fig:subtraction}, which shows the natural encoding of the left introduction rule for
    subtraction in sequent calculus into scroll nets. \WP{2} will prove that generalized scrolls
    lead to a sound and complete characterization of intuitionistic, bi-intuitionistic and classical
    logic by considering various restrictions on their shapes, as well as the topological properties
    of the graphs of inference rules that ensue. It will also ensure that the sequentialization and
    normalization results of \WP{1} extend well to this setting, which would constitute important
    contributions to both \CH{1} and \CH{2} by providing a non-trivial equational theory for
    classical and bi-intuitionistic proofs.

\begin{figure}
  \captionsetup[subfigure]{justification=centering}
  \centering
  \begin{subfigure}[b]{0.30\textwidth}
    $$\scalebox{0.85}{
    $\prftree[r]{$L{-}$}{\prfsummary[$\pi$]{\Gamma, A \vdash B, \Delta}}{\Gamma, A - B \vdash \Delta}$
    }$$
    $$\includepdf{4cm}{subtraction}$$
    \caption{Encoding intuitionistic subtraction}
    \label{fig:subtraction}
  \end{subfigure}
  \begin{subfigure}[b]{0.49\textwidth}
    $$\includepdf{8cm}{factorial}$$
    \caption{Encoding natural numbers and the factorial function}
    \label{fig:factorial}
  \end{subfigure}
  \begin{subfigure}[b]{0.2\textwidth}
    $$\includepdf{4cm}{modal}$$
    \caption{Proof in predicate modal logic of $\forall x. \square (p(x) \land q(x)) \vdash (\forall x. \square p(x)) \land (\forall x. \square q(x))$}
    \label{fig:modal}
  \end{subfigure}
  \caption{Extensions of scroll nets to richer logics (\WP{2} -- \WP{4})}
  \label{fig:extensions}
\end{figure}

    \item Once disjunction is properly handled by the results of \WP{2}, adding \emph{smallest} and
    \emph{greatest fixpoints} of propositions is a natural step to take, that would bring the
    computational power of state-of-the-art functional programming languages. Indeed, the
    combination of these two constructs corresponds to \emph{(co-)recursive algebraic data types}
    through the CHC, which are essential to express (co-)recursive computation on (infinite)
    tree-structured data. Fig.~\ref{fig:factorial} gives a proof-of-concept of how this could be
    implemented in scroll nets through the classic example of the factorial function. The idea is to
    enlarge the space of correct proofs by allowing \emph{self-reference} in inference rules, here
    represented by the arrow that calls the \texttt{fac} scroll into itself. \WP{3} will explore
    this idea further, addressing both \CH{2} and \KO{2}. 

    \item Work packages \WP{1} to \WP{3} deal with various flavours of propositional logic,
    corresponding to Peirce's system $\mathsf{Alpha}$ of EGs. However, Peirce also explored
    extensions of EGs with new diagrammatic constructs that go beyond the language of propositional
    logic: system $\mathsf{Beta}$ used so-called \emph{lines of identity} (LoI) to capture both
    quantifiers and equality in \emph{predicate logic}; while system $\mathsf{Gamma}$ was a more
    experimental attempt at capturing both \emph{modal} and \emph{higher-order} logics with a
    special kind of epistemic negation called ``broken cut'', represented by a dashed ellipse whose
    content should be interpreted as ``possibly not true''\footcite{maGammaGraphCalculi2018}. This
    is illustrated in Fig.~\ref{fig:modal}, where the left scroll can be read classically as $\neg
    \exists x. \diamond \neg (p(x) \land q(x))$ which is classically equivalent to the premiss
    $\forall x. \square (p(x) \land q(x))$: the LoI connecting $p$, $q$ and the outloop represents
    the universally quantified variable $x$, while the dashed inloop represents necessity. \WP{4}
    will explore the precise inference rules governing these constructs, trying to accomodate the
    partial descriptions left in Peirce's writings to the modern CHC conception inherent to scroll
    nets. We expect that LoI can express \emph{dependent product/sum} types and \emph{identity}
    types, while broken cuts could capture either type-theoretic \emph{modalities} or type-theoretic
    \emph{universes} (or both), thus contributing greatly to \KO{1}. \WP{4} will also be essential
    to reach the necessary expressive power to simulate CoIC, and thus situate scroll nets as a
    realistic new foundation for ITPs.

    \item The Functional Machine Calculus (FMC) and Relational Machine Calculus (RMC) are two
    foundational models of computation introduced very recently by W. Heijltjes, also co-inventor of
    intuitionistic combinatorial
    proofs\footcite{heijltjesFunctionalMachineCalculus2023,barrettRelationalMachineCalculus2024,heijltjes_intuitionistic_2019}.
    They achieve respectively a unification of the two main paradigms of declarative programming,
    \emph{functional} and \emph{logic} programming, with the more mainstream paradigm of
    \emph{imperative} programming. An open problem is to find a suitable combination of the FMC and
    RMC that could subsume all three paradigms. \WP{5} will explore the potential of scroll nets as
    a solution in the well-typed fragment, by devising translations of the FMC and RMC that preserve
    both its denotational and operational semantics. This will build on \WP{1} for the operational
    semantics given by detour elimination; \WP{2} to account for non-determinism and failure with
    $(n,1)$-scrolls for sum types ($n > 1$) and empty types ($n < 1$); \WP{3} to account for
    recursion of the Kleene star operator with smallest and greatest fixpoints; and \WP{4} to
    account for unification with LoI for dependent types.
\end{enumerate}

\paragraph{Interdisciplinarity} By incorporating the CHC at the heart of its methodology, {\proj} is
by its very nature interdisciplinary, placing itself at the crossroad of \textbf{mathematical logic}
and \textbf{programming language theory}. Although not the focus of this project, the long-term
vision of exploiting scroll nets as a medium for powerful and intuitive GUIs in ITPs warrants future
intersections with the field of \textbf{human-computer interaction} (HCI). Through its dealing with
the very foundations of the notion of formal proof, {\proj} also exhibits a strong
\textbf{philosophical} flavor, which will be technically realized through its systematic
hermeneutics of the original writings of C. S. Peirce on EGs. Peirce was probably one of the last
polymathic genius in the history of western science, and his broad holistic vision of logic as the
formal investigation of the principles of scientific inquiry certainly influences the ER's own
vision, putting {\proj} in the realm of bordering areas of philosophy like \emph{epistemology},
\emph{semiotics} and \emph{metaphysics}.

\paragraph{Gender}
Not applicable, because the research of {\proj} is of an abstract and theoretical nature.

\paragraph{Open science and research data management}
All the results of {\proj} will be made available as arXiv pre-prints, with the aim of encouraging
informal evaluation from the scientific community. Moreover, the ER will (co-)organise a workshop to
communicate results and encourage feedback from other researchers (Sec. 2.2). The project
deliverables will be published in the proceedings of high-rated and peer-reviewed conferences and in
scientific journals (Sec.~\ref{ssc:impact:outcomes}). Proceeding publications will be made
available on arXiv, and journal contributions will be published in Open Access format, for which
funding is foreseen. {\proj} does not envisage the collection of any kind of data, and eventual
software prototypes experimenting with an implementation of scroll nets will all be open-sourced.

% At a minimum, address the following aspects:

% \begin{itemize}
%     \item \emph{Overall methodology}: Describe and explain the overall methodology,
%     including the concepts, models and assumptions that underpin your work.
%     Explain how this will enable you to deliver your project’s objectives. Refer
%     to any important challenges you may have identified in the chosen methodology
%     and how you intend to overcome them.

%     \item \emph{Integration of methods and disciplines to pursue the objectives}:
%     Explain how expertise and methods from different disciplines will be brought
%     together and integrated in pursuit of your objectives. If you consider that
%     an inter-disciplinary\footnotemark{} approach is unnecessary in the
%     context of the proposed work, please provide a justification.

%     \footnotetext{\emph{Interdisciplinarity} means the integration of information,
%     data, techniques, tools, perspectives, concepts or theories from two or
%     more scientific disciplines.}

%     \item \emph{Gender dimension and other diversity aspects}: Describe how the
%     gender dimension and other diversity aspects are taken into account in the
%     project's research and innovation content. If you do not consider such a
%     gender dimension to be relevant in your project, please provide a
%     justification.
%     \begin{itemize}
%         \item Remember that that this question relates to the \emph{content} of the
%         planned research and innovation activities, and not to gender balance
%         in the teams in charge of carrying out the project.

%         \item  Sex, gender and diversity analysis refers to biological
%         characteristics and social/cultural factors respectively. For guidance on
%         methods of sex / gender analysis and the issues to be taken into account,
%         please refer to this
%         \href{https://op.europa.eu/en/publication-detail/-/publication/33b4c99f-2e66-11eb-b27b-01aa75ed71a1/language-en}{link}.
%     \end{itemize}

%     \item \emph{Open science practices}: Describe how appropriate open science
%     practices are implemented as an integral part of the proposed methodology.
%     Show how the choice of practices and their implementation is adapted to the
%     nature of your work in a way that will increase the chances of the project
%     delivering on its objectives \emph{[1/2 page]}. If you believe that none of
%     these practices are appropriate for your project, please provide a justification
%     here.

%     \emph{Open science is an approach based on open cooperative work and systematic
%     sharing of knowledge and tools as early and widely as possible in the process.
%     Open science practices include early and open sharing of research (for example
%     through pre-registration, registered reports, pre-prints, or crowd-sourcing);
%     research output management; measures to ensure reproducibility of research
%     outputs; providing open access to research outputs (such as publications,
%     data, software, models, algorithms, and workflows); participation in open
%     peer-review; and involving all relevant knowledge actors including citizens,
%     civil society and end users in the co-creation of R\&I agendas and contents
%     (such as citizen science).}

%     \emph{Please note that this does not refer to outreach actions that may be
%     planned as part of the communication, dissemination and exploitation activities.
%     These aspects should instead be described below under ``Impact''.}

%     \item Proposals selected for funding under Horizon Europe will need to develop
%     a detailed data management plan (DMP) for making their data/research outputs
%     findable, accessible, interoperable and reusable (FAIR) as a deliverable by
%     month 6 and revised towards the end of a project's lifetime. The DMP should
%     describe how research outputs (especially research data) generated and/or
%     collected during the project will be managed so as to ensure that they are
%     findable, accessible, interoperable and reusable.

%     \emph{For guidance on open science practices and research data management,
%     please refer to the relevant section of the
%     \href{https://ec.europa.eu/info/funding-tenders/opportunities/docs/2021-2027/horizon/temp-form/af/af_he-msca-pf_en.pdf}{HE Programme Guide}
%     on the Funding \& Tenders Portal.}
% \end{itemize}

\subsection{Quality of the supervision, training and of the two-way transfer of
    knowledge between the researcher and the host}
\label{ssc:excellence:supervision}

\paragraph{Quality of the supervision}
The project will be supervised by Anupam Das, associate professor at the School of Computer Science
of the University of Birmingham in the Theory of Computation (ToC) group. Prof. Das is a leading
expert in proof theory, who is nowadays particularly active in the area of cyclic proofs for
fixpoint logics (\WP{3}). He has a strong background in deep inference, linear logic and their
applications to complexity theory, and has also made multiple contributions to the study of
intuitionistic modal logics (\WP{4}). His supervision will thus be essential to the success of
{\proj}.

Prof. Das has an excellent record of almost 60 publications in top-tier journals (LMCS, JAR) and
peer-reviewed conference proceedings (LICS, CSL, FSCD, IJCAR, TABLEAUX) in logic, theoretical
computer science and automated theorem proving. He also has a good track record in mentoring young
researchers: he co-supervised 2 Ph.D. students with Prof. Escardo and Prof. Paul Levy --- with whom
the ER expects collaborations on \WP{4} and \WP{5} --- and supervised 5 postdocs thanks to the
funding that he obtained as a recipient of the UKRI Future Leaders Fellowship \textit{Structure vs.
Invariants in Proofs} (2020--2024, renewed for 2024--2027). He was himself an MSCA postdoctoral
fellow from 2017 to 2019.

\paragraph{Host-to-applicant transfer of knowledge}
The project will greatly benefit from the combined expertise of several leading researchers at ToC.
For \WP{2}, the ER will collaborate with Dr. Shillito, a postdoctoral fellow with internationally
recognized expertise in the syntax and semantics of bi-intuitionistic logic. For \WP{4}, the ER will
also collaborate with Dr. Marin and Prof. Escardo, eminent specialists in modal logics and dependent
types/homotopy type theory/ITPs, respectively. For the foundational work in \WP{1} and its
application in \WP{5}, the ER will collaborate with Prof. Ghica, who has been applying graphical
formalisms to model computations for several decades in both academia and industry. For \WP{5}, the
ER will additionally collaborate with Prof. Paul Levy, a renowned expert in effectful programming
languages. His groundbreaking work in this field was recognized with the 2025 Alonzo Church Award
for Outstanding Contributions to Logic and Computation.

\paragraph{Applicant-to-host transfer of knowledge}
The ER will bring to ToC his worldwide unique expertise on EGs and their proof theory, as well as
the application of deep inference and graphical proof theory to interactive theorem proving. He will
share his knowledge through one-to-one interactions with ToC members and students, by speaking at
seminars, by supervising Master projects and by (co-)organising a workshop on {\proj} topics
(Sec.~\ref{ssc:impact:outcomes}).

\paragraph{Training}
The ER's overarching career goal is to secure a computer science professorship in Europe. In the
medium term, he aspires to obtain an unsupervised temporary position and funding by an ERC starting
grant. The acquisition of a prestigious MSCA grant would significantly enhance his prospects. The
proposed training program developed with the supervisor is structured into five Training Objectives:
\begin{description}
    \item[\TO{1}. Gaining scientific knowledge]
    The {\proj} project will advance the ER's expertise in theoretical domains, complementing his
    practical software engineering skills obtained during his PhD through substantial implementation
    work of ITP technology. During his tenure at the host institution, the ER will expand his
    scientific horizon by immersing himself in the English school of proof theory, the historical
    centre for the development of the deep inference methodology. Here, he will gain further
    knowledge of advanced state-of-the-art topics such as cyclic proofs, intuitionistic modal logics
    and homotopy type theory. At least weekly meetings with his supervisor will serve as forums to
    assess project progress, explore scientific inquiries, and exchange innovative ideas.
    
    \item[\TO{2}. Developing communication and public outreach skills]

    \item[\TO{3}. Enhance management and leadership skills]

    \item[\TO{4}. Enhance supervision and teaching skills]

\end{description}   The ER will actively engage
in mentoring the supervisor's students, providing individual guidance on their research projects,
and offering courses in specialised subjects such as structural proof theory and interactive theorem
proving. He will also take on responsibilities such as crafting research internship proposals and
overseeing interns during 2-3 month periods of study. The ER will actively participate in the ToC's
weekly seminar series, featuring speakers from renowned global research institutions. Moreover, the
ER will be an active participant in the national monthly “Chocola” meetings held in Lyon. As a
fellowship recipient, the ER will also acquire grant management skills and enhance his grant
proposal writing abilities, supported by the Inria cell of the European Research Network.

\subsection{Quality and appropriateness of the researcher's professional
    experience, competences and skills}
\label{ssc:excellence:researcher}

Discuss the quality and appropriateness of the researcher’s existing professional
experience in relation to the proposed research project.

\section{Impact \mscatag{IMP-ACT-IA}}
\label{sc:impact}

\subsection{Credibility of the measures to enhance the career perspectives
    and employability of the researcher and contribution to his/her skills
    development}
\label{ssc:impact:career}

At a minimum, address the following aspects:

\begin{itemize}
    \item Specific measures to enhance career perspectives and employability of
    the researcher inside and/or outside academia.
    \item \emph{Expected} contribution of proposed skills development to the
    future career of the researcher.
\end{itemize}

\subsection{Suitability and quality of the measures to maximise expected
    outcomes and impacts, as set out in the dissemination and exploitation plan,
    including communication activities \mscatag{COM-DIS-VIS-CDV}}
\label{ssc:impact:outcomes}

At a minimum, address the following aspects:

\begin{itemize}
    \item \emph{Plan for the dissemination and exploitation activities, including
    communication activities}\footnotemark{}: Describe the planned measures to
    maximize the impact of your project by providing a first version of your ‘plan
    for the dissemination and exploitation including communication activities’.
    Describe the dissemination, exploitation measures that are planned, and the target
    group(s) addressed (e.g. scientific community, end users, financial actors,
    public at large). Regarding communication measures and public engagement
    strategy, the aim is to inform and reach out to society and show the activities
    performed, and the use and the benefits the project will have for citizens.
    Activities must be strategically planned, with clear objectives, start at the
    outset and continue through the lifetime of the project. The description of
    the communication activities needs to state the main messages as well as the
    tools and channels that will be used to reach out to each of the chosen target
    groups.

    \footnotetext{In case your proposal is selected for funding, a more detailed
    Dissemination and Exploitation plan will need to be provided as a mandatory
    project deliverable during project implementation.}

    \item \emph{Strategy for the management of intellectual property, foreseen
    protection measures}: if relevant, discuss the strategy for the management
    of intellectual property, foreseen protection measures, such as patents,
    design rights, copyright, trade secrets, etc., and how these would be used
    to support exploitation.

    \item All measures should be proportionate to the scale of the project, and
    should contain concrete actions to be implemented both during and after the
    end of the project.
\end{itemize}

\subsection{The magnitude and importance of the project’s contribution to the
    expected scientific, societal and economic impacts}
\label{ssc:impact:future}

\begin{itemize}
    \item Provide a narrative explaining how the project’s results are expected
    to make a difference in terms of impact, beyond the immediate scope and
    duration of the project. The narrative should include the components below,
    tailored to your project.

    \item Be specific, referring to the effects of your project, and not R\&I
    in general in this field. State the target groups that would benefit.

    \item The impacts of your project may be:

    \begin{itemize}
        \item \emph{Scientific}: e.g. contributing to specific scientific advances,
        across and within disciplines, creating new knowledge, reinforcing
        scientific equipment and instruments, computing systems (i.e. research
        infrastructures);

        \item \emph{Economic/technological}: e.g. bringing new
        products, services, business processes to the market, increasing efficiency,
        decreasing costs, increasing profits, contributing to standards’ setting,
        etc.

        \item \emph{Societal}: e.g. decreasing CO2 emissions,
        decreasing avoidable mortality, improving policies and decision-making,
        raising consumer awareness.
    \end{itemize}

    \item Only include such outcomes and impacts where your project would make
    a significant and direct contribution. Avoid describing very tenuous links
    to wider impacts.

    \item Give an indication of the magnitude and importance of the project's
    contribution to the expected outcomes and impacts, should the project be
    successful. Provide credible quantified estimates where possible and meaningful.

    ``Magnitude'' refers to how widespread the outcomes and impacts are likely
    to be. For example, in terms of the size of the target group, or the
    proportion of that group, that should benefit over time.

    ``Importance'' refers to the value of those benefits. For example, number of
    additional healthy life years; efficiency savings in energy supply.
\end{itemize}

\mscatagend{COM-DIS-VIS-CDV} \mscatagend{IMP-ACT-IA}

\section{Quality and Efficiency of the Implementation
         \mscatag{QUA-LIT-QL} \mscatag{WRK-PLA-WP} \mscatag{CON-SOR-CS} \mscatag{PRJ-MGT-PM}}
\label{sc:implementation}

\subsection{Quality and effectiveness of the work plan, assessment of risks and
    appropriateness of the effort assigned to work packages}
\label{ssc:implementation:workplan}

At a minimum, address the following aspects:

\begin{itemize}
    \item Brief presentation of the overall structure of the work plan,
    including deliverables and milestones.

    \item Timing of the different work packages and their components;

    \item Mechanisms in place to assess and mitigate risks (of research and/or
    administrative nature).
    
    \begin{table}[]
    \begin{tabular}{|l|c|c|}
    \hline
    \textbf{Risk}                                                                                    & \textbf{Mitigation}                                                                                                                   & \textbf{Severity} \\ \hline
    The FMC or RMC's expressivity makes it difficult to find an efficient simulation in scroll nets. & Close collaboration with the original inventor W. Heijltjes, or fallback to smaller results on less expressive models of computation. & high              \\ \hline
                                                                                                     &                                                                                                                                       &                   \\ \hline
    \end{tabular}
    \end{table}
\end{itemize}

A Gantt chart must be included and should indicate the proposed Work Packages
(WP), major deliverables, milestones, secondments, placements, if applicable.
This Gantt chart counts towards the 10-page limit.

The schedule in the Gantt chart should indicate the number of months elapsed
from the start of the action (Month 1, Month 2, etc.), but no actual dates.

\subsection{Quality and capacity of the host institutions and participating
organisations, including hosting arrangements}
\label{ssc:implementation:host}

At a minimum, address the following aspects:

\begin{itemize}
    \item Hosting arrangements, including integration in the team/institution(s)
    and support services available to the researcher.

    \item Quality and capacity of the participating organisations, including
    infrastructure, logistics and facilities. Additional information should be
    outlined in Part B-2 Section 5 (``Capacity of the Participating Organisations'').
\end{itemize}

Note that for GF, both the quality and capacity of the outgoing Third Country
host and the return host should be outlined.

\subsection*{Associated partners linked to a beneficiary {\protect\footnotemark{}}}
\label{ssc:implementation:partners}

If applicable, outline here the involvement of any 'associated partners linked
to a beneficiary' (in particular, the name of the entity, the type of link with
the beneficiary and the tasks to be carried out).

\footnotetext{See the definitions section of the MSCA Work Programme for
further information.}

\mscatagend{CON-SOR-CS} \mscatagend{PRJ-MGT-PM} \mscatagend{QUA-LIT-QL} \mscatagend{WRK-PLA-WP}
\end{document}

% kate: default-dictionary en_GB;
